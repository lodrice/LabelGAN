{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorian/.local/lib/python3.5/site-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
      "  warn('Viewer requires Qt')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from skimage import io, filters\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from lgan.diffeomorphism import tf_diffeomorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 #batch size\n",
    "input_dim = 784 #dim x and z input_size\n",
    "\n",
    "#mnist data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_train = X_train.reshape(55000,28,28,1)\n",
    "\n",
    "#reorganize labels\n",
    "y_train = np.zeros(55000)\n",
    "for i in range(len(Y_train)):\n",
    "    y_train[i]= np.argwhere(Y_train[i]==1)#reshape\n",
    "\n",
    "#create mean Images\n",
    "numberImages = np.zeros((10,28,28,1))\n",
    "for i in range(10):\n",
    "    numbers = np.argwhere(y_train==i)\n",
    "    z = X_train[numbers] #collect all images with number    \n",
    "    numberImages[i] = np.mean(z, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(55000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMsAAADYCAYAAABFuRcGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQoQFCP0Pp3enlB6I6JgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81a810ec50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMsAAADYCAYAAABFuRcGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvwFYl+g5FIbllQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81a8240828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMsAAADYCAYAAABFuRcGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACYhJREFUeJzt3U9P1tkZxvHrqIyKgAqKKEINJibaxbyILvommrRJt910\n14VJ07SrvodOJn0BTZfd9Q3MxpiJCxO0jYoo8sc/iIA8XdRJSOZ33Vw8gz4i389Kzo8jx8e55pe5\n5z7ntF6vJwB7OzboBQCHBWEBQoQFCBEWIERYgBBhAUKEBQgRlgFprf2utfZda+1da+3bPb739621\np621l621b1prJz/RMrELYRmcJ5L+Iumb6ptaa7+U9AdJv5D0M0lzkv700VeHHyEsA9Lr9f7R6/X+\nKenFHt/6a0l/6/V63/d6vRVJf5b0m4+9PvwYYfn8/VzSnV1f35F0qbU2MaD1HFmE5fM3Imlt19c/\n/Hp0AGs50gjL5++1pLFdX//w61cDWMuRRlg+f99L+nrX119LWuz1env9tw4OGGEZkNbaidbaKUnH\nJR1vrZ1qrZ3o+Na/S/pta+1Wa+2cpNuSvv2ES8UHhGVwbkt6q/+XhX/14de3W2uzrbXXrbVZSer1\nev+S9FdJ/5b0X0n/kfTHwSz5aGts/gIyvFmAEGEBQoQFCBEWIERYgFBXXd9qrR350llrzT4bGhrq\nHB8bG+scl6Tp6enO8Zs3b9o5t27dss+uX7/eOX78+HE7Z35+vnP87t27ds6dO3c6xxcXF+2c9fX1\nzvHNzU07Z2dnp3P8oKu4vV7P/8V+wJsFCBEWIERYgBBhAUKEBQjtqxqG/qphw8PDds74+Hjn+MWL\nF+2c6tnIyEjn+PLysp3jKliPHj2yc9zvt7GxYedsb2/bZ4cBbxYgRFiAEGEBQoQFCBEWIEQ1bJ+O\nHfP/fjl5svtU1ao37NKlS53jly9ftnMmJyftsxMnuv9Kl5aW7JynT5/ua1yS3r592zn+/v17O+ew\n480ChAgLECIsQIiwACHCAoQICxCidGy4hklXmpWkU6dOdY5XjY/9lI7PnTtnn62srHSOV2Vg1zD5\n6pU/e9xt960+H1d239rasnPc9uFBHA7JmwUIERYgRFiAEGEBQoQFCFENM1w1zG0dlqSzZ892jk9N\nTdk57pC9qhpWreH58+ed4wsLC3aO2yJcNY267csV12TpmjIl6d27d53j/VTQfireLECIsAAhwgKE\nCAsQIixAiLAAIUrHhrvP5MyZM3aOa5isysCzs7Od41Wz5Js3b+wzVyJ2DZaSPzvANXlK0ldffdU5\nXu3Bd+t++fKlnfP69evOcdfIWa3hp5aUebMAIcIChAgLECIsQIiwAKEjXQ2r7lpx1Z7R0VE758qV\nK53jMzMzds7Vq1c7x12FSpIePnxon62urnaOuz+PJF27dq1zvKr8uWbOqsFxbW2tc7xq8nTboau7\nXlxjJtUw4BMhLECIsAAhwgKECAsQIixA6EiXjqs95u50yYmJCTvHlY7n5ubsHLdvv2qWfPHihX3m\nyqNubZJ0/vz5fa1N8o2m1X56d6HS6dOn7RzXFFmVqN2zzc1NOyfBmwUIERYgRFiAEGEBQoQFCB3p\napir6Ei+idA1Pkq+YbLanuvuM+nnlEZJGh8f7xyvqnhu3dXWZlelcqdbSnVjprO+vt45Xt0d4z67\nqoKW4M0ChAgLECIsQIiwACHCAoQICxA6EqVj1zBZNfD1c7qk28s+NjZm57iTFavScbVuVyJ2a5Pq\nErGzsbHROV41p7pys/u9JH9aZdVM6ppQq5+T4M0ChAgLECIsQIiwACHCAoSORDWsn7tWXNWr2p47\nOTnZOV6dLunuH6lOT7xw4YJ95qp4VUXO/ayqYdM9q6phbpty9edxVS/3WUv+enP3Wad4swAhwgKE\nCAsQIixAiLAAIcIChI5E6djtc68aEt1e9qmpKTvHlUarvf6ubOtOxJTqi4n62dPfzz53p1q3uwCp\nauR0z0ZGRuwc96y63jzBmwUIERYgRFiAEGEBQoQFCH0x1bCq4uQqNO5eEslXtlyVTJKGh4c7x6tG\nSre2ak51z4jbOls1EbrGw6qC5tZdNTi6OVVV0j2rPh/3rKoiJnizACHCAoQICxAiLECIsAAhwgKE\nvpjScbX325UMq2Y8VwauypyuibEqc7pzAFxzo+RPdpR8ibg6wdGd+lidA+AaHKumSFc63t7etnPc\n/xJwn7XkP2/XyJnizQKECAsQIixAiLAAIcIChA5dNay1tq/xT/lzXEWuqsKMjo52jlfXUFfVMNdk\n6X5O9aya45pQqwqjW/fq6uq+51SVuo+FNwsQIixAiLAAIcIChAgLECIsQOjQlY6dqpHSqfayu4bE\ntbU1O8eVe6tys2v6qy74qRoz3dkBMzMzdo777KpzDdyzqqTrSsTuKm7JnwPQz0VLVcNmgjcLECIs\nQIiwACHCAoQICxAiLEDoiykdV2VBV0qsul2XlpY6xx88eGDnuPJsdQe96+ytLgWqzgFw5euqU9k9\n66e7uboAyZXdFxcX7Rz391CV8F3Zf2dnx85J8GYBQoQFCBEWIERYgBBhAUKHrhrmGvWqSoerhrlK\niyTdv3+/c7y6EMc1F1Zrm52d7Ryv9r9XDY5OtQZXSawuM3JVr4WFBTvn3r17nePz8/N2zuPHjzvH\nnzx5Yue4xsyqcTbBmwUIERYgRFiAEGEBQoQFCBEWINT2cwxma+3Tn5l5ANwe8+pCHHeZkdvjLknT\n09Od4zdu3LBz5ubmOsddSVmSpqam7DN3fGp1DoArrS8vL9s5rnRblXSfPXvWOV41UrrS8crKip3j\nytpVKXx9fX3P8395swAhwgKECAsQIixAiLAAoSNRDeuHqx5VTYxuu2+1rXh8fLxzfGJiws6pKnLV\ndmTHNVlWzZcbGxud49W2YneFeLW9211xXlW23Nbqauv51tYW1TDgoBAWIERYgBBhAUKEBQgRFiBE\n6fgAuXJz1cTomjyry5mqZ+5nVadYDg0N7ev3knxZeY/y7L7nuFMxq39u3dqqOe/fv6d0DBwUwgKE\nCAsQIixAiLAAIaphX5h+KnLVM2c//9zsNWfQP//DM6phwEEhLECIsAAhwgKECAsQIixA6NBdZoSa\nK4/2U2r9VD7nte3GmwUIERYgRFiAEGEBQoQFCBEWIERYgBBhAUKEBQgRFiBEWIAQYQFChAUIERYg\nRFiAEGEBQoQFCBEWIERYgBBhAUKEBQgRFiBEWIAQYQFChAUIERYgRFiAEGEBQoQFCBEWIERYgBBh\nAUKEBQgRFiBEWIAQYQFChAUIERYg1A7LtcrAoPFmAUKEBQgRFiBEWIAQYQFChAUIERYgRFiAEGEB\nQoQFCP0Pp3enlB6I6JgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81a810ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#try Diffeomorphism\n",
    "image = numberImages[6]\n",
    "image = np.reshape(image, (1,28,28,1))\n",
    "print(image.shape)\n",
    "session = tf.InteractiveSession()\n",
    "diff_map =  np.random.uniform(-0.6,0.6, size=(1,2, 2, 2)) #batch_size, diff_height, diff_width, 2\n",
    "dif_image = tf_diffeomorphism(image,diff_map)\n",
    "plot(image,np.zeros(1))\n",
    "div_image = dif_image.eval()\n",
    "plot(div_image,np.ones(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple plot function\n",
    "def plot(samples, labels):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1, top=1.3,\n",
    "                wspace=None, hspace=None)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.title(labels[i])\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')   \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample for Generator: Random Mean Images 0-9 + Uniform Noise Vector + Label\n",
    "def sample_z(batch_size):\n",
    "    batch = np.zeros((batch_size,input_dim))\n",
    "    labels = np.zeros((batch_size,))\n",
    "    for i in range(batch_size-1):\n",
    "        vector = np.random.uniform(-1., 1., size=[input_dim])/20\n",
    "        index = int(np.random.rand(1)*10)\n",
    "        number = np.reshape(numberImages[index],784)\n",
    "        z_im = number+vector\n",
    "        batch[i]=z_im\n",
    "        labels[i]=index\n",
    "    return (batch,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    with tf.variable_scope('generator'):\n",
    "        z = tf.reshape(z,[-1,28,28,1])\n",
    "        net = slim.conv2d(z, 32, [3, 3],2, weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                          scope='convG_1',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 64, [3, 3],1, weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                          scope='convG_2',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.convolution2d_transpose(net, 32, [3,3],2, weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                          scope='convG_3',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 1, [1,1],1, weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                          scope='convG_4',padding = 'SAME')\n",
    "        G_prob = tf.nn.tanh(net)\n",
    "        return G_prob\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        x = tf.reshape(x,[-1,28,28,1])\n",
    "        #net = slim.conv2d(x, 128, [3, 3], weights_initializer=tf.contrib.layers.xavier_initializer(), scope='convD_1')\n",
    "        #net = slim.batch_norm(net)\n",
    "        #net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(x, 32, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          scope='convD_2',padding = 'SAME')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 64, [3, 3],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          scope='convD_3',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.convolution2d_transpose(net, 32, [3,3],2, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          scope='convD_4',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 16, [3,3],1, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          scope='convD_5',padding = 'SAME')\n",
    "        net = slim.batch_norm(net)\n",
    "        net = tf.nn.relu(net)\n",
    "        return slim.fully_connected(net, num_outputs = 1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "#input\n",
    "X = tf.placeholder(tf.float32, shape=[None, input_dim]) \n",
    "z = tf.placeholder(tf.float32, shape=[None, input_dim])\n",
    "\n",
    "#Models\n",
    "G_sample = generator(z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample)\n",
    "\n",
    "#variables V1\n",
    "theta_D1 = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator') \n",
    "theta_G1 = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "\n",
    "D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "D_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(-D_loss, var_list=theta_D1))\n",
    "G_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(G_loss, var_list=theta_G1))\n",
    "\n",
    "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D1]\n",
    "\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "#initalize Variables    \n",
    "sess.run(tf.global_variables_initializer())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pretrain disc:\n",
    "for t in range(100):\n",
    "    #train discriminator\n",
    "    Xdata, _ = mnist.train.next_batch(batch_size)\n",
    "    (im, labels) = sample_z(batch_size) #get Image Batch+Labels\n",
    "    print(\"Pretrain Step \",t)\n",
    "    _, D_loss_curr, _ = sess.run(\n",
    "        [D_solver, D_loss, clip_D],\n",
    "        feed_dict={X: Xdata, z: im}\n",
    "    ) \n",
    "    \n",
    "i = 0\n",
    "for it in range(100000):\n",
    "    for _ in range(5): #train discriminator\n",
    "        Xdata, _ = mnist.train.next_batch(batch_size)\n",
    "        (im, labels) = sample_z(batch_size) #get Image Batch+Labels\n",
    "        _, D_loss_curr, _ = sess.run(\n",
    "            [D_solver, D_loss, clip_D],\n",
    "            feed_dict={X: Xdata, z: im}\n",
    "        )\n",
    "    (im, labels) = sample_z(batch_size) #get Image Batch+Labels\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={z: im}\n",
    "    )\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "        if it % 1000 == 0:\n",
    "            (im, labels) = sample_z(16) #get Image Batch+Labels\n",
    "            samples = sess.run(G_sample, feed_dict={z: im})\n",
    "            print(samples[0].shape)\n",
    "            fig = plot(samples, labels)\n",
    "            plt.savefig('out/{}.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            plt.show()\n",
    "            i += 1\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
