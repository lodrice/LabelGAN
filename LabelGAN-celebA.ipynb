{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage import io, filters\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os,sys\n",
    "from lgan.diffeomorphism import tf_diffeomorphism\n",
    "from tqdm import tqdm\n",
    "from scipy import misc\n",
    "from keras.preprocessing import image\n",
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper-parameter\n",
    "data_size = 100\n",
    "batch_size = 32 #batch size\n",
    "input_dim = 128 #dim http://localhost:8889/notebooks/MyGans/LabelGAN/LabelGAN-celebA.ipynb#x and z input_size\n",
    "image_size = 4096\n",
    "attribute_size = 40\n",
    "imX= 64\n",
    "imY= 64\n",
    "LAMBDA = 10\n",
    "output_dim = imX*imY*3\n",
    "\n",
    "#Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batcher = datagen.flow_from_directory(\n",
    "    directory='/home/ben/celeba/resized',\n",
    "    target_size= (64, 64),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode= None,\n",
    "    batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#annotations\n",
    "attr_file  = open('/home/ben/celeba/Anno/list_attr_celeba.txt', \"r\")\n",
    "attributes = np.zeros((data_size,attribute_size))\n",
    "attr = attr_file.readline() #get different attributes\n",
    "attr = attr.split(\" \")[0:attribute_size] #40 annotations\n",
    "\n",
    "for i in range(data_size):\n",
    "    a = attr_file.readline()\n",
    "    a = a.split(\" \")\n",
    "    a = np.array(list(filter(lambda x:x!=\"\",a))) #filter empty strings\n",
    "    a = np.array(list(map(float, a[1:attribute_size+1])))\n",
    "    attributes[i]=a\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#simple plot function\n",
    "def plot(samples, labels,y,x):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(y, x)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1, top=1.5,\n",
    "                wspace=None, hspace=None)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.title(labels[i])\n",
    "        plt.imshow(sample)   \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Resize Images - only do once\n",
    "def resize():\n",
    "    path = '/home/ben/celeba/data/0'\n",
    "    dirs = os.listdir( path )    \n",
    "    for item in dirs:\n",
    "        if os.path.isfile(os.path.join(path,item)):\n",
    "            image = ndimage.imread(os.path.join(path,item), mode=\"RGB\")\n",
    "            image_resized = misc.imresize(image, (64, 64))\n",
    "            misc.imsave('/home/ben/celeba/resized/0/'+item, image_resized)\n",
    "\n",
    "#resize()\n",
    "print(len(os.listdir(\"/home/ben/celeba/resized/0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getImageBatch():\n",
    "    img_batch = batcher.next()\n",
    "    if len(img_batch) != batch_size:\n",
    "        img_batch = batcher.next()\n",
    "    assert len(img_batch) == batch_size\n",
    "    return img_batch\n",
    "\n",
    "plot(getImageBatch(),np.zeros(batch_size),8,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create mean Images\n",
    "#todo: sort image - attributes\n",
    "#creates just nonsense means\n",
    "meanImages = np.zeros((attribute_size,imY,imX,3))\n",
    "for i in range(attribute_size):\n",
    "    image_batch = getImageBatch()  \n",
    "    meanImages[i] = np.mean(image_batch, axis=0)\n",
    "plot(meanImages, np.zeros(attribute_size),10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#toDO -how to do means`?\n",
    "def getMeanImage(batch_size):\n",
    "    indexes = (np.random.rand(batch_size)*20).astype(int)\n",
    "    images= meanImages[indexes]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_z(batch_size):\n",
    "    batch = np.zeros((batch_size,input_dim))\n",
    "    #labels = np.zeros((batch_size,10)) \n",
    "    for i in range(batch_size):\n",
    "        vector = np.random.uniform(-1., 1., size=[input_dim]) #create noise vector of 128\n",
    "        #index = int(np.random.rand(1)*10)\n",
    "        #labels[i][index]= 1  #get random label \n",
    "        batch[i] = vector\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convLayer(layerinput, maps, kernel, stride,scope, act=\"relu\"):\n",
    "    layerinput = slim.conv2d(layerinput, maps, kernel,stride, weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                  scope=scope,padding = 'SAME')\n",
    "    if(act == \"tanh\"):        \n",
    "        return tf.nn.tanh(layerinput)\n",
    "    else:\n",
    "        layerinput = slim.batch_norm(layerinput)\n",
    "        return tf.nn.relu(layerinput) \n",
    "    \n",
    "def leakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha*x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generator Variables\n",
    "scalar = tf.Variable(tf.reduce_mean(tf.random_normal([1], stddev=1)))\n",
    "multMatrix = tf.Variable(tf.random_normal([batch_size,2,256], stddev=1))\n",
    "\n",
    "#Generator - add Detail\n",
    "def generator_detail(noise, dif_image):\n",
    "    with tf.variable_scope('generator_detail'):\n",
    "        noise = tf.reshape(noise, (batch_size,64,2))\n",
    "        noise = tf.matmul(noise, multMatrix) #49x16 Matrix=784\n",
    "        noise = tf.reshape(noise,(batch_size, 32,32,16))\n",
    "        noise = slim.batch_norm(noise)\n",
    "        #noise = tf.scalar_mul(scalar, noise)\n",
    "\n",
    "        details = tf.reshape(dif_image, [batch_size, 64,64,3])\n",
    "        details = convLayer(details, 16, [3,3],2, scope='convReshape_1')\n",
    "        \n",
    "        detail_image = tf.add(details, noise)\n",
    "        detail_image = convLayer(detail_image, 1024, [9,9],8, scope='convDetail_0')\n",
    "        detail_image = slim.convolution2d_transpose(detail_image, 512, [3,3],2)\n",
    "        detail_image = slim.batch_norm(detail_image)\n",
    "        detail_image = tf.nn.relu(detail_image)\n",
    "        detail_image = slim.convolution2d_transpose(detail_image, 256, [3,3],2)\n",
    "        detail_image = slim.batch_norm(detail_image)\n",
    "        detail_image = tf.nn.relu(detail_image)        \n",
    "        detail_image = slim.convolution2d_transpose(detail_image, 128, [3,3],2)\n",
    "        detail_image = slim.batch_norm(detail_image)\n",
    "        detail_image = tf.nn.relu(detail_image)\n",
    "        detail_image = slim.convolution2d_transpose(detail_image, 3, [3,3],2) \n",
    "        detail_image = tf.nn.tanh(detail_image)\n",
    "\n",
    "        return detail_image\n",
    "'''\n",
    "#Generator - predict parameters for Diffeomorphism\n",
    "def generator_dif_paras(noise_vector):\n",
    "    with tf.variable_scope('generator_diffeo'):\n",
    "        params = tf.reshape(noise_vector,[batch_size,16,8,1])\n",
    "        params = convLayer(params, 32, [3, 3],2, scope='convG_1')  \n",
    "        params = convLayer(params, 1, [3, 3],2, scope='convG_2')\n",
    "        params = tf.nn.tanh(params)\n",
    "        params= tf.reshape(params, [batch_size,2,2,2]) \n",
    "        return params\n",
    "'''    \n",
    "#Main Generator\n",
    "def generator(z, mean_image):\n",
    "    with tf.variable_scope('generator'):\n",
    "        mean_image = tf.reshape(mean_image,[batch_size, imY,imX,3])\n",
    "        #class_z = slim.fully_connected(class_z, input_dim,weights_initializer=tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        #class_z = tf.nn.relu(class_z)\n",
    "        #class_z = tf.nn.relu(z)\n",
    "        #noise = tf.add(z,class_z)\n",
    "        \n",
    "        #dif_params = generator_dif_paras(z)\n",
    "        #dif_image = tf_diffeomorphism(mean_image,dif_params) \n",
    "        detailed_image = generator_detail(z, mean_image)\n",
    "        return [detailed_image,mean_image]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v1 fully conv\n",
    "def discriminator(x):\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        x = tf.reshape(x,[batch_size,imY,imX,3])\n",
    "        net = slim.conv2d(x, 16, [4, 4],2, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(x, 32, [3, 3],2, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 128, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 128, [3, 3],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 256, [5, 5],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 512, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 512, [3,3],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None) \n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 1024, [3,3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None) \n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 1, [2,2],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)       \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#V2: autoencoder\n",
    "def encoder(x):\n",
    "    with tf.variable_scope('auto_disc'):\n",
    "        x = tf.reshape(x,[batch_size,imY,imX,3])\n",
    "        net = slim.conv2d(x, 64, [3, 3],1, weights_initializer=tf.contrib.layers.xavier_initializer(), scope='convD_1')\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(x, 128, [3, 3],1, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 256, [3, 3],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 512, [3, 3],1,weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.fully_connected(net, 128, activation_fn=None,weights_initializer=tf.truncated_normal_initializer(stddev=0.1))  \n",
    "        return net\n",
    "    \n",
    "def decoder(x):\n",
    "    with tf.variable_scope('auto_disc'):\n",
    "        \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input\n",
    "Mean_image = tf.placeholder(tf.float32, shape=[batch_size, imY,imX,3])\n",
    "X = tf.placeholder(tf.float32, shape=[batch_size,imY,imX,3]) \n",
    "Z = tf.placeholder(tf.float32, shape=[batch_size, input_dim]) #random Noise 100\n",
    "#Class_z = tf.placeholder(tf.float32, shape=[batch_size, attribute_size]) #class(label) of image\n",
    "\n",
    "#Models\n",
    "detail_image = generator(Z, Mean_image) \n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(detail_image[0])\n",
    "\n",
    "#variables V1\n",
    "theta_D = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator') \n",
    "theta_G = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "\n",
    "\n",
    "D_losses, G_losses = [],[]\n",
    "\n",
    "D_loss = tf.reduce_mean(D_fake) - tf.reduce_mean(D_real)\n",
    "#added simple L1 Loss.\n",
    "G_l1_loss = tf.multiply(0.001, tf.reduce_mean(tf.abs(detail_image[0]-detail_image[1])))\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "#improved WGAN without weight clipping. Instead penalizing gradient \n",
    "alpha = tf.random_uniform(shape=[batch_size,1], minval=0.,maxval=1.)\n",
    "\n",
    "differences = tf.reshape(detail_image[0] - X, (batch_size, output_dim))\n",
    "interpolates = tf.reshape(X,(batch_size, output_dim)) + (alpha*differences)\n",
    "interpolates = tf.reshape(interpolates, (batch_size, 64,64,3))\n",
    "gradients = tf.gradients(discriminator(interpolates), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "D_loss += LAMBDA*gradient_penalty\n",
    "\n",
    "G_losses.append(G_loss)\n",
    "D_losses.append(D_loss)\n",
    "\n",
    "G_loss = tf.add_n(G_losses)\n",
    "D_loss = tf.add_n(D_losses) \n",
    "\n",
    "#Solver\n",
    "D_solver = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(D_loss, var_list=theta_D, colocate_gradients_with_ops=True))\n",
    "G_solver = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(G_loss, var_list=theta_G, colocate_gradients_with_ops=True))\n",
    "\n",
    "\n",
    "if not os.path.exists('out-celebA/'):\n",
    "    os.makedirs('out-celebA/')\n",
    "\n",
    "#initalize Variables    \n",
    "sess.run(tf.global_variables_initializer())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "logs_path = 'logs/lgan-log'\n",
    "\n",
    "if not os.path.exists('logs/'):\n",
    "    os.makedirs('logs/')\n",
    "#Instantiate Tensorboard\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"D-loss\", D_loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"G-loss\", G_loss)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pretrain disc:\n",
    "for t in tqdm(range(50)):\n",
    "    #train discriminator\n",
    "    Xdata = getImageBatch()\n",
    "    z = sample_z(batch_size) #get Image Batch+Labels\n",
    "    mean_image = getMeanImage(batch_size) #get mean_image\n",
    "    _, D_loss_curr = sess.run(\n",
    "        [D_solver, D_loss],\n",
    "        feed_dict={X: Xdata, Z:z, Mean_image:mean_image}\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "d_costs = []\n",
    "g_costs = []\n",
    "for it in range(100000):\n",
    "    for q in range(5): #train discriminator\n",
    "        Xdata = getImageBatch()\n",
    "        z = sample_z(batch_size) #get Image Batch+Labels\n",
    "        _, D_loss_curr = sess.run(\n",
    "            [D_solver, D_loss],\n",
    "            feed_dict={X: Xdata, Z:z, Mean_image:mean_image}\n",
    "        )\n",
    "        d_costs.append(D_loss_curr)\n",
    "    z = sample_z(batch_size) #get Image Batch+Labels\n",
    "    mean_image = getMeanImage(batch_size) #get mean_image\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={Z:z, Mean_image:mean_image}\n",
    "    )\n",
    "    g_costs.append(G_loss_curr)\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "        if it % 1000 == 0:\n",
    "            z = sample_z(batch_size) #get Image Batch+Labels\n",
    "            mean_image = getMeanImage(batch_size) #get mean_image\n",
    "            samples = sess.run(detail_image, feed_dict={Z:z,Mean_image:mean_image})         \n",
    "            samples[0] = np.reshape(samples[0], (batch_size,64,64,3))\n",
    "            fig = plot(samples[0][:16], np.zeros(16),4,4)\n",
    "            plt.savefig('out-celebA/{}.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            plt.show()\n",
    "            i += 1\n",
    "        else:\n",
    "            z = sample_z(batch_size) #get Image Batch+Labels\n",
    "            mean_image = getMeanImage(batch_size) #get mean_image\n",
    "            samples = sess.run(detail_image, feed_dict={Z:z,Mean_image:mean_image})         \n",
    "            samples[0] = np.reshape(samples[0], (batch_size,imY,imX,3))\n",
    "            fig = plot(samples[0][:4],np.zeros(4),1,4)\n",
    "            plt.show()\n",
    "            \n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(d_costs[500:_])\n",
    "plt.ylabel('D_Loss')\n",
    "plt.show()\n",
    "plt.savefig('out-celebA/DLoss.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "\n",
    "plt.plot(g_costs[500:_])\n",
    "plt.ylabel('G_Loss')\n",
    "plt.show()\n",
    "plt.savefig('out-celebA/GLoss.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
