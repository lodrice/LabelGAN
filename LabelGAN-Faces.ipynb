{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage import io, filters\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os,sys\n",
    "from lgan.diffeomorphism import tf_diffeomorphism\n",
    "from tqdm import tqdm\n",
    "from scipy import misc\n",
    "from keras.preprocessing import image\n",
    "from scipy import ndimage, misc\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PREROCESS IMAGES - only do once\n",
    "def resizeFaces():\n",
    "    path = '/home/dorian/MyGans/LabelGAN/faces_only'\n",
    "    dirs = os.listdir( path )    \n",
    "    for item in dirs:\n",
    "        if os.path.isfile(os.path.join(path,item)):\n",
    "            inread = ndimage.imread(os.path.join(path,item), mode=\"RGB\")\n",
    "            image_cut = inread[0:900,200:1100,:] #cut image:1333x1013->900x900\n",
    "            image_resized = misc.imresize(image_cut, (64, 64))\n",
    "            misc.imsave('/home/dorian/MyGans/LabelGAN/faces/0/'+item, image_resized)\n",
    "    \n",
    "            \n",
    "def cutImages():\n",
    "    path = '/home/ben/celeba/data/0'\n",
    "    dirs = os.listdir( path )    \n",
    "    for item in dirs:\n",
    "        if os.path.isfile(os.path.join(path,item)):\n",
    "            inread = ndimage.imread(os.path.join(path,item), mode=\"RGB\")\n",
    "            image_cut = inread[40:198,10:168,:] #cut image:218x179->158x158\n",
    "            image_resized = misc.imresize(image_cut, (64, 64))\n",
    "            misc.imsave('/home/ben/celeba/cut/0/'+item, image_resized)\n",
    "            \n",
    "\n",
    "#resizeFaces()\n",
    "\n",
    "print(len(os.listdir(\"/home/ben/celeba/cut/0\")))\n",
    "print(len(os.listdir('/home/dorian/MyGans/LabelGAN/faces/0/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper-parameter\n",
    "data_size = 202599\n",
    "batch_size = 32 #batch size\n",
    "input_dim = 10 \n",
    "image_size = 4096\n",
    "imX= 64\n",
    "imY= 64\n",
    "LAMBDA = 10\n",
    "output_dim = imX*imY*3\n",
    "\n",
    "#Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple plot function\n",
    "def plot(samples, labels,y,x):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(y, x)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1, top=1.5,\n",
    "                wspace=None, hspace=None)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.title(labels)\n",
    "        plt.imshow(sample)   \n",
    "    return fig\n",
    "\n",
    "\n",
    "#images plotted while learning\n",
    "def preprocessPlotImages(samples):\n",
    "    images = np.zeros((batch_size,imY,imX,3))\n",
    "    for i in range(batch_size):\n",
    "        befor = copy.copy(samples[1][i])\n",
    "        after = copy.copy(samples[0][i])\n",
    "        befor_reshape = misc.imresize(befor, (20,20))/255\n",
    "        after[44:64,44:64]=befor_reshape\n",
    "        images[i]=after\n",
    "    return images\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batcher_celeb = datagen.flow_from_directory(\n",
    "    directory='/home/ben/celeba/cut',\n",
    "    target_size= (64, 64),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode= None,\n",
    "    batch_size= batch_size)\n",
    "\n",
    "batcher_faces = datagen.flow_from_directory(\n",
    "    directory='/home/dorian/MyGans/LabelGAN/faces',\n",
    "    target_size= (64, 64),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode= None,\n",
    "    batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getImageBatch():\n",
    "    img_batch = batcher_celeb.next()\n",
    "    if len(img_batch) != batch_size:\n",
    "        img_batch = batcher_celeb.next()\n",
    "    assert len(img_batch) == batch_size\n",
    "    return img_batch\n",
    "\n",
    "def getFacesBatch():\n",
    "    img_batch = batcher_faces.next()\n",
    "    if len(img_batch) != batch_size:\n",
    "        img_batch = batcher_faces.next()\n",
    "    assert len(img_batch) == batch_size\n",
    "    return img_batch\n",
    "  \n",
    "facebatch = getFacesBatch()\n",
    "plot(facebatch[0:16], \"GenImage\",4,4)\n",
    "plt.show()\n",
    "celeb = getImageBatch()\n",
    "plot(celeb[0:16], \"CelebA Image\",4,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(batch_size):\n",
    "    batch = np.zeros((batch_size,input_dim))\n",
    "    for i in range(batch_size):\n",
    "        vector = np.random.uniform(-1., 1., size=[input_dim]) #create noise vector of 128\n",
    "        batch[i] = vector\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha*x, x)\n",
    "\n",
    "def resnet_block(inputs, maps=64, kernel=[3, 3],stride=1):\n",
    "    layer = slim.conv2d(inputs, maps, kernel, stride,weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                  padding = 'SAME',activation_fn=None)\n",
    "    layer = slim.batch_norm(layer)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = slim.conv2d(layer, maps, kernel, stride,weights_initializer=tf.truncated_normal_initializer(stddev=1e-1),\n",
    "                  padding = 'SAME',activation_fn=None)\n",
    "    layer = slim.batch_norm(layer)\n",
    "    outputs = tf.add(inputs, layer)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simGenerator(image, noise):\n",
    "    image = tf.reshape(image,[batch_size,imY,imX,3])\n",
    "    noise = slim.fully_connected(noise, 4096,weights_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    noise = tf.reshape(noise, [batch_size,imY,imX,1])\n",
    "    net = tf.concat([image, noise],3)\n",
    "    net = slim.conv2d(net, 64, [3,3],1)\n",
    "    net = resnet_block(net, maps=64, kernel=[3, 3],stride=1)\n",
    "    net = resnet_block(net, maps=64, kernel=[3, 3],stride=1)\n",
    "    net = resnet_block(net, maps=64, kernel=[3, 3],stride=1)\n",
    "    net = resnet_block(net, maps=64, kernel=[3, 3],stride=1)\n",
    "    net = resnet_block(net, maps=64, kernel=[3, 3],stride=1)\n",
    "    net = slim.conv2d(net, 32, [3,3],1)\n",
    "    net = slim.conv2d(net, 3, [1,1],1)\n",
    "    return tf.nn.tanh(net)\n",
    "\n",
    "#Main Generator\n",
    "def generator(face_image, z):\n",
    "    with tf.variable_scope('generator'):\n",
    "        face_image = tf.reshape(face_image,[batch_size, imY,imX,3])\n",
    "        #dif_params = generator_dif_paras(z)\n",
    "        #dif_image = tf_diffeomorphism(face_image,dif_params)\n",
    "        detailed_image = simGenerator(face_image,z)\n",
    "        return [detailed_image,face_image]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        x = tf.reshape(x,[batch_size,imY,imX,3])\n",
    "        x = slim.conv2d(x, 16, [4, 4],2, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        x = leakyReLU(x)\n",
    "        net = slim.conv2d(x, 32, [3, 3],2, weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 128, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 256, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)\n",
    "        net = leakyReLU(net)\n",
    "        #net = slim.conv2d(net, 256, [3, 3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "        #                 padding = 'SAME',activation_fn=None)\n",
    "        #net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 512, [3,3],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None) \n",
    "        net = leakyReLU(net)\n",
    "        net = slim.conv2d(net, 1, [2,2],2,weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                         padding = 'SAME',activation_fn=None)   \n",
    "        return [net,tf.nn.relu(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictStartImage(blurImage):\n",
    "    with tf.variable_scope('predictor'):\n",
    "        genImage = slim.conv2d(blurImage,16, [5,5],2,activation_fn=None)\n",
    "        genImage = slim.batch_norm(genImage)\n",
    "        genImage = tf.nn.relu(genImage)\n",
    "        genImage = slim.conv2d(genImage, 32, [5,5],2,activation_fn=None)\n",
    "        genImage = slim.batch_norm(genImage)\n",
    "        genImage = tf.nn.relu(genImage)\n",
    "        genImage = slim.convolution2d_transpose(genImage, 64, [3,3],2,activation_fn=None)\n",
    "        genImage = slim.batch_norm(genImage)\n",
    "        genImage = tf.nn.relu(genImage)\n",
    "        genImage = slim.convolution2d_transpose(genImage,32, [3,3],2,activation_fn=None)\n",
    "        genImage = slim.batch_norm(genImage)\n",
    "        genImage = tf.nn.relu(genImage)\n",
    "        genImage = slim.convolution2d_transpose(genImage,3, [3,3],2)\n",
    "        return tf.nn.tanh(genImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBlurImages(faces,z):\n",
    "    samples = sess.run(face_images, feed_dict={Face:faces,Z:z})\n",
    "    samples_blur = np.zeros((batch_size,imY,imX,3))\n",
    "    for i,s in enumerate(samples[0]):\n",
    "        samples_blur[i]= ndimage.filters.gaussian_filter(samples[0][i],1.0)\n",
    "        samples_blur[i] = samples[0][i]\n",
    "    return samples_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#create bool mask\n",
    "mask = np.ones((batch_size,imY,imX,3))\n",
    "for y in range(imY):\n",
    "    for x in range(imX):\n",
    "        if y+x<=20:\n",
    "            mask[:,y,x,:]=0\n",
    "        if x+(imY-y)<=20:\n",
    "            mask[:,(imY-y),x,:]=0\n",
    "        if (imX-x)+y<=20:\n",
    "            mask[:,y,(imX-x),:]=0\n",
    "        if(imX-x)+(imY-y)<=20:\n",
    "            mask[:,(imY-y),(imX-x),:]=0\n",
    "plt.imshow(mask[0])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#input\n",
    "Face = tf.placeholder(tf.float32, shape=[batch_size, imY,imX,3])\n",
    "X = tf.placeholder(tf.float32, shape=[batch_size,imY,imX,3])\n",
    "Z = tf.placeholder(tf.float32, shape=[batch_size, input_dim])\n",
    "#Blur = tf.placeholder(tf.float32, shape=[batch_size,imY,imX,16])\n",
    "\n",
    "#Models\n",
    "face_images = generator(Face, Z ) \n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(face_images[0])\n",
    "predictImage = predictStartImage(D_fake[1])\n",
    "\n",
    "    \n",
    "#variables V1\n",
    "theta_D = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator') \n",
    "theta_G = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "theta_Pred = sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'predictor')\n",
    "\n",
    "\n",
    "D_losses, G_losses = [],[]\n",
    "\n",
    "#meanSquaredErrorLoss for Predictor:\n",
    "P_loss = tf.reduce_sum(tf.squared_difference(predictImage, Face))\n",
    "\n",
    "#Discriminator Wasserstein-Loss\n",
    "D_loss = tf.reduce_mean(D_fake[0]) - tf.reduce_mean(D_real[0])\n",
    "\n",
    "#Generator L1-Loss\n",
    "G_l1_loss = tf.reduce_sum(tf.abs(face_images[0]-face_images[1]))\n",
    "\n",
    "#Generator Loss\n",
    "G_loss = -tf.reduce_mean(D_fake[0])+tf.multiply(0.1,P_loss)\n",
    "\n",
    "\n",
    "#improved WGAN without weight clipping. Instead penalizing gradient \n",
    "alpha = tf.random_uniform(shape=[batch_size,1], minval=0.,maxval=1.)\n",
    "\n",
    "differences = tf.reshape(face_images[0] - X, (batch_size, output_dim))\n",
    "interpolates = tf.reshape(X,(batch_size, output_dim)) + (alpha*differences)\n",
    "interpolates = tf.reshape(interpolates, (batch_size, 64,64,3))\n",
    "gradients = tf.gradients(discriminator(interpolates), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "D_loss += LAMBDA*gradient_penalty\n",
    "\n",
    "G_losses.append(G_loss)\n",
    "D_losses.append(D_loss)\n",
    "\n",
    "G_loss = tf.add_n(G_losses)\n",
    "D_loss = tf.add_n(D_losses) \n",
    "\n",
    "#Solver\n",
    "D_solver = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(D_loss, var_list=theta_D, colocate_gradients_with_ops=True))\n",
    "G_solver = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(G_loss, var_list=theta_G, colocate_gradients_with_ops=True))\n",
    "G_solver_L1 = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(G_l1_loss, var_list=theta_G, colocate_gradients_with_ops=True))\n",
    "P_solver = (tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5, beta2=0.9)\n",
    "            .minimize(P_loss, var_list=theta_Pred, colocate_gradients_with_ops=True))\n",
    "\n",
    "\n",
    "if not os.path.exists('out-imdb-faces/'):\n",
    "    os.makedirs('out-imdb-faces/')\n",
    "\n",
    "\n",
    "#initalize Variables \n",
    "#Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "if os.path.isfile(\"checkpoints-celeba/model-celeba.index\"):\n",
    "    # Restore variables from disk.\n",
    "    print(\"Restore variables\")\n",
    "    saver.restore(sess, \"checkpoints-celeba/model-celeba\")\n",
    "else:\n",
    "    print(\"Instantiate variables\")\n",
    "    sess.run(tf.global_variables_initializer())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pretrain gen with L1 Loss:\n",
    "for t in tqdm(range(0)): \n",
    "    faces = getFacesBatch()\n",
    "    z = sample_z(batch_size)\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver_L1, G_l1_loss],\n",
    "        feed_dict={Face:faces,Z:z}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pretrain disc:\n",
    "for t in tqdm(range(0)):\n",
    "    #train discriminator\n",
    "    Xdata = getImageBatch()\n",
    "    faces = getFacesBatch()\n",
    "    z = sample_z(batch_size)\n",
    "    _, D_loss_curr = sess.run(\n",
    "        [D_solver, D_loss],\n",
    "        feed_dict={X: Xdata, Face:faces,Z:z}\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#pretrain predictor\n",
    "for t in tqdm(range(0)):\n",
    "    faces = getFacesBatch()\n",
    "    z = sample_z(batch_size)\n",
    "    _, P_loss_curr = sess.run(\n",
    "        [P_solver, P_loss],\n",
    "        feed_dict={Face:faces,Z:z}\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "d_costs = []\n",
    "g_costs = []\n",
    "for it in range(100000):\n",
    "    for q in range(5): #train discriminator\n",
    "        Xdata = getImageBatch()\n",
    "        faces = getFacesBatch()\n",
    "        z = sample_z(batch_size)\n",
    "        _, D_loss_curr = sess.run(\n",
    "            [D_solver, D_loss],\n",
    "            feed_dict={X: Xdata,Face:faces,Z:z}\n",
    "        )\n",
    "        d_costs.append(D_loss_curr)\n",
    "    #trainGenerator \n",
    "    faces = getFacesBatch()\n",
    "    z = sample_z(batch_size)  \n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={Face:faces,Z:z}\n",
    "    )\n",
    "    g_costs.append(G_loss_curr)\n",
    "    #trainPredictor\n",
    "    _, P_loss_curr = sess.run(\n",
    "        [P_solver, P_loss],\n",
    "        feed_dict={Face:faces,Z:z}\n",
    "    ) \n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}; D loss: {:.4}; G_loss: {:.4}; P_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr,P_loss_curr))\n",
    "        faces = getFacesBatch()\n",
    "        z = sample_z(batch_size)\n",
    "        samples = sess.run(face_images, feed_dict={Face:faces,Z:z})  \n",
    "        imagesToPlot = preprocessPlotImages(samples)\n",
    "        if it % 1000 == 0:\n",
    "            fig = plot(imagesToPlot[:16],\"GenImage\",4,4)\n",
    "            plt.savefig('out-imdb-faces/{}.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            plt.show()\n",
    "            #save variables\n",
    "            save_path = saver.save(sess, \"checkpoints-celeba/model-celeba\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            i += 1\n",
    "        else:\n",
    "            baseImages = sess.run(predictImage, feed_dict={Face:faces,Z:z})\n",
    "            \n",
    "            fig = plot(imagesToPlot[:4],\"GenImage\",1,4)\n",
    "            plt.show()           \n",
    "            fig2 = plot(baseImages[:4],\"PredictImage\",1,4)\n",
    "            plt.show()\n",
    "            \n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(d_costs[500:_])\n",
    "plt.ylabel('D_Loss')\n",
    "plt.show()\n",
    "plt.savefig('out-celebA/DLoss.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "\n",
    "plt.plot(g_costs[500:_])\n",
    "plt.ylabel('G_Loss')\n",
    "plt.show()\n",
    "plt.savefig('out-celebA/GLoss.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
